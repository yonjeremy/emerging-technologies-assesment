{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognition\n",
    "![Image of machine learniing](https://cdn-images-1.medium.com/max/1200/1*M9le42saJxWlOYyYvhKtPA.jpeg)\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. Introduction to supervised machine learning\n",
    "2. The task\n",
    "3. MNIST\n",
    "4. Keras\n",
    "5. First Trial\n",
    "6. Second Trial\n",
    "7. Third Trial\n",
    "8. Results and Conclusion\n",
    "9. References\n",
    "\n",
    "## Introduction to supervised machine learning\n",
    "\n",
    "**Supervised machine learning [1]** is when an algorithm recieves an input, and figures out a way to map those inputs to an output. A simple formula would be $y = f(x)$ where x are the input variables, and y are the output variables.\n",
    "\n",
    "The reason why its \"supervised\" is because the algorithm has to be taught, in the same way a teacher teaches a student math principles, and from there on the algorithm will make its own conclusions. Supervised learning requires that the algorithm’s possible outputs are already known and that the data used to train the algorithm is already labeled with correct answers. \n",
    "\n",
    "In this notebook, we will learn how to use the supervised machine learning algorithm in the form of Keras to read the MNIST dataset.\n",
    "\n",
    "## The task\n",
    "\n",
    "Objective : \n",
    "To write a script that takes an image file containing a handwritten digit and identify the digit using a supervised learning algorithm.\n",
    "\n",
    "The problem: \n",
    "This is a digital recognition task. The challenge is to code a script that will achieve an acuuracy of about 99%, as effectively and efficiently as possible (CPU limits).\n",
    "\n",
    "Methodology:\n",
    "Run the experiment in 3 trials. Record the results in the first experiment, and make variations in the next 2 experiments.\n",
    "\n",
    "## Mnist\n",
    "**The MNIST dataset [2]** is a database that contains a training set of 60,000 examples, and a test set of 10,000 examples, of hand written digits. It stands for the Mixed National Institute of Standards and Technology. It is used for training image processing systems.\n",
    "\n",
    "A full explanation of the Mnist dataset can be found on my **MNIST notebook [3]**.\n",
    "\n",
    "## Keras\n",
    "![Image of keras](https://keras.io/img/keras-logo-small-wb.png)\n",
    "\n",
    "**Keras [4]** \"is a high-level neural networks API, written in Python and capable of running on top of TensorFlow, CNTK, or Theano\", according to the official Keras website. It is an API tool that allows quick and easy experimentation, and it has convulational networks.\n",
    "\n",
    "The reason why we chose Keras is because it is user friendly. We are able to create a machine learning model in just a few lines of code. It also runs seamlessly between GPU and CPU.  Hence, prototypes can be created in a jiffy.\n",
    "\n",
    "## First trial\n",
    "\n",
    "### 1. Reading in the Mnist dataset\n",
    "\n",
    "The MNIST dataset is read into the script using gzip, using the example from my previous notebook [3]. \n",
    "\n",
    "The training images array is reshaped into 60000, 28 * 28 images. This is done using the reshape() function. The pixels are also reversed with the ~ symbol, so that the foreground will be black and the background will be white. The pixels are divided by 255 so that the algorithm will be more accurate when taking in numbers from range 0-1 instead of 0-255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2089c4517f0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Open the training images\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "# Open the training labels\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()\n",
    "\n",
    "# Reshape the training images to an array of 60000, of which the picture is 28 by 28 pixels.\n",
    "# The pixels are divided by 255 so that the algorithm will be more accurate when taking in numbers from range \n",
    "#  0-1 instead of 0-255\n",
    "# The pixels are also flipped around with the ~ symbol so that the foreground will be black and the \n",
    "#  background will be white\n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "\n",
    "# The training labels are put into a list, starting from position 8 in the array, ignorning the metadata\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)\n",
    "\n",
    "# Display the first image in the training image array\n",
    "plt.subplot(221)\n",
    "plt.imshow(train_img[0], cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fix the random seed\n",
    "\n",
    "The random seed is fixed so that the results can be reproduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Flatten the input\n",
    "\n",
    "The training dataset is structured as a 3d array of instance, image width and image height. For a \"multi-layer perceptron model\" we must reduce the images down into a vector of pixels. In this case the 28×28 sized images will be 784 pixel input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into one linear input of pixels\n",
    "inputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Encode the variables categorically \n",
    "\n",
    "Finally, the output variable is an integer from 0 to 9. This is a multi-class classification problem. As such, we should encode the class values, transforming the vector of class integers into a binary matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[1 0 0 0 0 0 0 0 0 0]]\n",
      "1 [[0 1 0 0 0 0 0 0 0 0]]\n",
      "2 [[0 0 1 0 0 0 0 0 0 0]]\n",
      "3 [[0 0 0 1 0 0 0 0 0 0]]\n",
      "4 [[0 0 0 0 1 0 0 0 0 0]]\n",
      "5 [[0 0 0 0 0 1 0 0 0 0]]\n",
      "6 [[0 0 0 0 0 0 1 0 0 0]]\n",
      "7 [[0 0 0 0 0 0 0 1 0 0]]\n",
      "8 [[0 0 0 0 0 0 0 0 1 0]]\n",
      "9 [[0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# For encoding categorical variables.\n",
    "import sklearn.preprocessing as pre\n",
    "\n",
    "encoder = pre.LabelBinarizer()\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)\n",
    "\n",
    "for i in range(10):\n",
    "    print(i, encoder.transform([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Model\n",
    "\n",
    "We will now create our simple model.The model will be created using the Sequential() model built into keras.\n",
    "\n",
    "The model is a simple neural network with one hidden layer and the same number of neurons as there are inputs (784). The input layer uses a linear activation function.\n",
    "\n",
    "The softmax activation dunction is used on the output layer. Logarithmic loss is used as the loss function (called categorical_crossentropy in Keras) and the efficient ADAM gradient descent algorithm is used to learn the weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras.\n",
    "import keras as kr\n",
    "\n",
    "# Start a neural network, building it by layers.\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with an input layer with 784.\n",
    "model.add(kr.layers.Dense(784, activation='linear', input_dim=784, kernel_initializer='normal'))\n",
    "# Add the output layer\n",
    "model.add(kr.layers.Dense(10, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fit the model\n",
    "\n",
    "Now, we will fit the model. The model has 2 epochs, so the training will run twice, and update every 100 images.\n",
    "\n",
    "This step might take a about half a minute depending on the CPU/GPU capabilities on the user's machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 5.2659 - acc: 0.5911\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 3.4042 - acc: 0.7059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2089c299630>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(inputs, outputs, epochs=2, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test the model\n",
    "\n",
    "Finally, we can test the model. We will first read in the test datasets using gzip.\n",
    "\n",
    "Next, the predict() function will determine if the test image will match the test label. The number of test images predicted correctly is printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8165"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the test images dataset\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "# read the test labels dataset\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "    \n",
    "# reshape the test images array into the correct shape and format as the train array\n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "# The test labels are put into a list, starting from position 8 in the array, ignorning the metadata\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)\n",
    "\n",
    "# get sum of correct predictions\n",
    "(encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Further testing\n",
    "\n",
    "This test is to see the accuracy of the model in predicting a random image in the test dataset. We will pick the tenth image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    }
   ],
   "source": [
    "print(encoder.inverse_transform(model.predict(test_img[17:18])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2089d8128d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADaVJREFUeJzt3X+oXPWZx/HPE01R0yiRjCaY6K0hxEalaR3igmFxWSx2ifkBVpo/SoSQ5I8IqZQYCYFGZeGybJP1j6Vwuwm5Qpqk2GZzhbDbKItuQYMTkcY2u00I1zQmJBOMmIpS9T79456Ua7zznXHOmTlz7/N+QZiZ85wfD0c/98zMd2a+5u4CEM+UshsAUA7CDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqGu7ebCZM2d6X19fNw8JhDI8PKyLFy9aK+vmCr+ZPSzpeUnXSPoPd+9Prd/X16darZbnkAASqtVqy+u2/bTfzK6R9O+SvidpoaRVZraw3f0B6K48r/kXSzrp7qfc/S+S9klaXkxbADotT/hvk/SnMY/PZMu+wMzWmVnNzGr1ej3H4QAUKU/4x3tT4UvfD3b3AXevunu1UqnkOByAIuUJ/xlJc8c8niPpbL52AHRLnvC/KWm+mX3DzL4m6QeShoppC0CntT3U5+6fmdkTkv5bo0N9u9z994V1BqCjco3zu/shSYcK6gVAF/HxXiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4LKNUuvmQ1Luizpc0mfuXu1iKYAdF6u8Gf+wd0vFrAfAF3E034gqLzhd0m/MbOjZrauiIYAdEfep/0PuPtZM7tF0mEz+z93f23sCtkfhXWSdPvtt+c8HICi5Lryu/vZ7PaCpAOSFo+zzoC7V929WqlU8hwOQIHaDr+ZTTOz6VfuS/qupHeKagxAZ+V52n+rpANmdmU/v3D3/yqkKwAd13b43f2UpG8V2AuALmKoDwiK8ANBEX4gKMIPBEX4gaAIPxBUEd/qmxAOHTqUrK9cuTJZ//TTT4ts5wuuv/76ZH3ZsmVt7/uOO+5I1jdu3JisHzlyJFmfOXNmsr5kyZJkHeXhyg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQYUZ5z99+nSy3slx/GY+/vjjZH3//v0dO/aOHTuS9WbnZcqU9PXj/vvvb1h79NFHk9suXLgwWe/r60vWFyxYkKxHx5UfCIrwA0ERfiAowg8ERfiBoAg/EBThB4IKM86/Zs2aZH3q1KnJ+smTJxvW8k5D1mycf2hoKNf+U44fP56s1+v1ZH1kZCRZf/3119uqteK6665L1jdt2tSw9swzz+Q69mTAlR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgjJ3T69gtkvSUkkX3P2ebNnNkvZL6pM0LOkxd7/U7GDVatVrtVrOllGkY8eOJeuHDx/Otf+9e/c2rB09ejTXvpu58cYbG9befffd5LY33XRT0e10RbVaVa1Ws1bWbeXKv1vSw1cte1rSK+4+X9Ir2WMAE0jT8Lv7a5Lev2rxckmD2f1BSSsK7gtAh7X7mv9Wdz8nSdntLcW1BKAbOv6Gn5mtM7OamdWafU4cQPe0G/7zZjZbkrLbC41WdPcBd6+6e7VSqbR5OABFazf8Q5JWZ/dXSzpYTDsAuqVp+M1sr6TXJS0wszNmtkZSv6SHzOyEpIeyxwAmkKbj/EVinD+eTz75pGHtvffeS27b35++puzcubOtniRp69atyfqzzz7b9r7LVPQ4P4BJiPADQRF+ICjCDwRF+IGgCD8QVJif7kY5Uj+vPW/evOS2mzdvTtabDfVNnz69Ye3xxx9PbhsBV34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpxfvSsgwfz/UbM5cuXG9ZefPHF5LZPPfVUrmNPBFz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvlRmlOnTiXr27Zty7X/1BTda9euzbXvyYArPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E1XSc38x2SVoq6YK735Mt2yZpraR6ttoWdz/UqSYxOb300kvJ+kcffZRr/6mx/BkzZuTa92TQypV/t6SHx1m+w90XZf8IPjDBNA2/u78m6f0u9AKgi/K85n/CzH5nZrvMjOdQwATTbvh/JmmepEWSzkn6aaMVzWydmdXMrFav1xutBqDL2gq/u59398/dfUTSzyUtTqw74O5Vd69WKpV2+wRQsLbCb2azxzxcKemdYtoB0C2tDPXtlfSgpJlmdkbSTyQ9aGaLJLmkYUnrO9gjgA5oGn53XzXO4vTE6EDmxIkTDWtbt27Nte8bbrghWV+zZk2u/U92fMIPCIrwA0ERfiAowg8ERfiBoAg/EBQ/3Y1cLl68mKxv2rSpYS3vV3afe+65ZP2uu+7Ktf/Jjis/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOD9y6e/vT9aHhoba3vedd96ZrG/cuLHtfYMrPxAW4QeCIvxAUIQfCIrwA0ERfiAowg8ExTg/kvbt25es79ixo+19T5s2LVk/cOBAsj5lCteuPDh7QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU03F+M5sr6QVJsySNSBpw9+fN7GZJ+yX1SRqW9Ji7X+pcq+iEV199NVlfv359su7ubR979+7dyfq9997b9r7RXCtX/s8k/djdvynp7yRtMLOFkp6W9Iq7z5f0SvYYwATRNPzufs7d38ruX5Z0XNJtkpZLGsxWG5S0olNNAijeV3rNb2Z9kr4t6YikW939nDT6B0LSLUU3B6BzWg6/mX1d0q8k/cjdP/wK260zs5qZ1er1ejs9AuiAlsJvZlM1Gvw97v7rbPF5M5ud1WdLujDetu4+4O5Vd69WKpUiegZQgKbhNzOTtFPScXffPqY0JGl1dn+1pIPFtwegU1r5Su8Dkn4o6ZiZvZ0t2yKpX9IvzWyNpNOSvt+ZFpHHBx98kKwvXbo0Wc87jfaGDRsa1pYtW5Zr38inafjd/beSrEH5H4ttB0C38Ak/ICjCDwRF+IGgCD8QFOEHgiL8QFD8dPckMDIy0rA2ODjYsCblH8e/7777kvXt27c3rE2dOjXXsZEPV34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/kngjTfeaFh78sknO3rszZs3J+uM5fcurvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/BPAhx+mZ0d75JFH2t53sym2lyxZkqyvWMH8rBMVV34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrpOL+ZzZX0gqRZkkYkDbj782a2TdJaSfVs1S3ufqhTjUb28ssvJ+uXLl1qe9/NxvH37t2brF97LR8Vmaha+S/3maQfu/tbZjZd0lEzO5zVdrj7v3auPQCd0jT87n5O0rns/mUzOy7ptk43BqCzvtJrfjPrk/RtSUeyRU+Y2e/MbJeZzWiwzTozq5lZrV6vj7cKgBK0HH4z+7qkX0n6kbt/KOlnkuZJWqTRZwY/HW87dx9w96q7VyuVSgEtAyhCS+E3s6kaDf4ed/+1JLn7eXf/3N1HJP1c0uLOtQmgaE3Db2Ymaaek4+6+fczy2WNWWynpneLbA9Aprbzb/4CkH0o6ZmZvZ8u2SFplZoskuaRhSes70iF09913J+uzZs1qWJs/f35y2z179iTrc+bMSdYxcbXybv9vJdk4Jcb0gQmMT/gBQRF+ICjCDwRF+IGgCD8QFOEHguL7mBPAggULkvWzZ892qRNMJlz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoazZFc6EHM6tLenfMopmSLnatga+mV3vr1b4kemtXkb3d4e4t/V5eV8P/pYOb1dy9WloDCb3aW6/2JdFbu8rqjaf9QFCEHwiq7PAPlHz8lF7trVf7kuitXaX0VuprfgDlKfvKD6AkpYTfzB42s/83s5Nm9nQZPTRiZsNmdszM3jazWsm97DKzC2b2zphlN5vZYTM7kd2OO01aSb1tM7P3snP3tpn9U0m9zTWz/zGz42b2ezPbmC0v9dwl+irlvHX9ab+ZXSPpj5IeknRG0puSVrn7H7raSANmNiyp6u6ljwmb2d9L+rOkF9z9nmzZv0h63937sz+cM9x9c4/0tk3Sn8ueuTmbUGb22JmlJa2Q9LhKPHeJvh5TCeetjCv/Ykkn3f2Uu/9F0j5Jy0voo+e5+2uS3r9q8XJJg9n9QY3+z9N1DXrrCe5+zt3fyu5flnRlZulSz12ir1KUEf7bJP1pzOMz6q0pv13Sb8zsqJmtK7uZcdyaTZt+Zfr0W0ru52pNZ27upqtmlu6Zc9fOjNdFKyP8483+00tDDg+4+3ckfU/ShuzpLVrT0szN3TLOzNI9od0Zr4tWRvjPSJo75vEcST3zI3Tufja7vSDpgHpv9uHzVyZJzW4vlNzP3/TSzM3jzSytHjh3vTTjdRnhf1PSfDP7hpl9TdIPJA2V0MeXmNm07I0Ymdk0Sd9V780+PCRpdXZ/taSDJfbyBb0yc3OjmaVV8rnrtRmvS/mQTzaU8W+SrpG0y93/uetNjMPM7tTo1V4a/WXjX5TZm5ntlfSgRr/1dV7STyT9p6RfSrpd0mlJ33f3rr/x1qC3BzX61PVvMzdfeY3d5d6WSPpfScckjWSLt2j09XVp5y7R1yqVcN74hB8QFJ/wA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1F8BOYXi8LSbwdUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(test_img[17].reshape(28, 28), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model is accurate enough to predict the number 7 from the test image.\n",
    "\n",
    "### 9.Conclusion from first trial\n",
    "\n",
    "From the results of the first trial, we can conclude that the model is working at about 80% accuracy. It made 8165 correct predictions and predicted digit of the random image correctly.\n",
    "\n",
    "80% is a good start, but we want to try to get the system up to a 99% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second trial\n",
    "\n",
    "### 1. Setting up a new model\n",
    "\n",
    "In the first trial model, we used a linear activation. Through research, I've found that switiching the activation to relu will drastically improve performance.\n",
    "\n",
    "Relu, or Rectified Linear Unit is the improved linear activations. It basically includes a max value and threshold to return a more accurate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a neural network, building it by layers.\n",
    "model2 = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with an input layer with 784 with activation RELU\n",
    "model2.add(kr.layers.Dense(784, activation='relu', input_dim=784, kernel_initializer='normal'))\n",
    "# Add the output layer\n",
    "model2.add(kr.layers.Dense(10, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. More epochs\n",
    "The new model will be set to 10 epochs, so the training will run ten times, and update every 100 images.\n",
    "\n",
    "This step will take 5 times longer to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 0.5544 - acc: 0.8379\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.3161 - acc: 0.9057\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.2499 - acc: 0.9247\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.2021 - acc: 0.9399\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.1737 - acc: 0.9479\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.1479 - acc: 0.9555\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.1353 - acc: 0.9587\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 0.1206 - acc: 0.9631\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 17s 286us/step - loss: 0.1162 - acc: 0.9643\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s 295us/step - loss: 0.1048 - acc: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20889ac8ef0>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model2.fit(inputs, outputs, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Testing new model\n",
    "\n",
    "We will run the new model by using the same test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9664"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the test images dataset\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "# read the test labels dataset\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "    \n",
    "# reshape the test images array into the correct shape and format as the train array\n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "# The test labels are put into a list, starting from position 8 in the array, ignorning the metadata\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)\n",
    "\n",
    "# get sum of correct predictions\n",
    "(encoder.inverse_transform(model2.predict(test_img)) == test_lbl).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conclusion from Second Trial\n",
    "\n",
    "From the results, we can observe a big jump in effciency of the new model. The model predicted 9646 images correctly compared to 8165 from the first model. \n",
    "\n",
    "The model is about 96% accurate, but takes a longer time to train the neural network.\n",
    "\n",
    "\n",
    "## Third trial\n",
    "\n",
    "### 1. Setting up new model with more layers\n",
    "\n",
    "This time, we will set up the model with new layers. In the previous models, the models were set up with an input layer and output layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a neural network, building it by layers.\n",
    "model3 = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with 600 neuros and  with input 784 with activation RELU\n",
    "model3.add(kr.layers.Dense(units=600, activation='relu', input_dim=784, kernel_initializer='normal'))\n",
    "# Add second hidden layer with 600 neuros and  with input 784 with activation RELU\n",
    "model3.add(kr.layers.Dense(units = 400, activation='relu', kernel_initializer='normal'))\n",
    "# Add the output layer\n",
    "model3.add(kr.layers.Dense(10, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "# Build the graph.\n",
    "model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decreasing batch size\n",
    "\n",
    "Now, we will fit the model with a batch size of 50, instead of 100. The model has 10 epochs, so the training will ten times, and update every 50 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 30s 503us/step - loss: 0.1219 - acc: 0.9613\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 30s 499us/step - loss: 0.0992 - acc: 0.9679\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.0904 - acc: 0.9706\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 31s 518us/step - loss: 0.0826 - acc: 0.9729\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 30s 501us/step - loss: 0.0729 - acc: 0.9755\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 31s 523us/step - loss: 0.0714 - acc: 0.9765\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 32s 527us/step - loss: 0.0729 - acc: 0.9763\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 32s 532us/step - loss: 0.0656 - acc: 0.9779\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 32s 527us/step - loss: 0.0663 - acc: 0.9780\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 31s 523us/step - loss: 0.0608 - acc: 0.9805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2088732df28>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(inputs, outputs, epochs=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Testing new model\n",
    "We will run the new model by using the same test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9705"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the test images dataset\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "# read the test labels dataset\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "    \n",
    "# reshape the test images array into the correct shape and format as the train array\n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "# The test labels are put into a list, starting from position 8 in the array, ignorning the metadata\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)\n",
    "\n",
    "# get sum of correct predictions\n",
    "(encoder.inverse_transform(model3.predict(test_img)) == test_lbl).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Conclusion from Third Trial\n",
    "\n",
    "From the results, we can observe a small jump in effeciency of the new model. The model predicted 9705 images correctly compared to 9646 from the 2nd model. \n",
    "\n",
    "The model is about 97% accurate, but it took a long time to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Analysis and Conclusion\n",
    "\n",
    "From our results, we managed to achieve about 97% accuracy. This is slightly below the target percentage accuracy of 99%, but it's still a feat using a simple linear network.\n",
    "\n",
    "For future research, the model should be set up with a **Simple Convolutional Neural Network [6]** which will take a bit more time to set up, but is more sophisticated and accurate.\n",
    "\n",
    "Below is the results of our research in graphical form. It is based of our previous experiments, as well as few others with different variables.\n",
    "\n",
    "Case A: Linear Activations, Epochs 2,  hidden layer 1, Batch size 100 <br>\n",
    "Case B: Relu Activations,   Epochs 2,  hidden layer 1, Batch size 100 <br>\n",
    "Case C: Relu Activations,   Epochs 10, hidden layer 1, Batch size 100<br>\n",
    "Case D: Relu Activations,   Epochs 10, hidden layer 2, Batch size 100<br>\n",
    "Case E: Relu Activations,   Epochs 10, hidden layer 2, Batch size 50<br>\n",
    "\n",
    "The most effective change came from Changing the Linear activations to relu activations, and changing the epochs from 2 to 10\n",
    "\n",
    "Finally, thanks to Dr Ian McLoughlin for supplying most of the **code snippets [7]** that can be found on his github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHvFJREFUeJzt3X+8VVWd//HXW1AENAW7lvzQTFFLv8VX8VeZOZmKTCNqmvitJMekaSyz71Rqj2+Dk/rIZizL0SwcTdRCSTMZIxFt1H74AzA00AwUFYQQBX9SJvT5/rHWre313svhxzl7wX0/H4/zuOesvfbea+977nmfvfba+yoiMDMzK81mdTfAzMysMw4oMzMrkgPKzMyK5IAyM7MiOaDMzKxIDigzMyuSA8qaRtJVks6rad2S9H1JKyTd38n0j0q6rY62bQwkHSJpUeX1XEmHtGC9tb1nNiRJIWnXutuxsXNA9SCSnpC0VFL/StknJd1ZY7Oa5SDgMGBIROzXcWJE/CAiDm99szZOEbFnRNy5pno98YNZ0p2SPll3OzZFDqiepzfwubobsbYk9VrLWXYCnoiIV5rRno2JpN51t6Eknb2X1uH9ZS3ggOp5/gP4gqRtO06Q9Lb8Dbh3peyv3w4lfULSryRdJOl5SY9Lek8uXyjpGUljOyz2zZKmS3pJ0l2Sdqose488bbmkRyV9pDLtKkmXSZoq6RXg7zpp7yBJU/L88yWdmstPAf4LOFDSy5L+rZN5PyHpl5XXIemfJc3LbT1X0i6S7pH0oqTJkrbIdQdIukXSstyFeIukIZVl7Szp7ryc2yVdKunayvQDJP0678MHq11nuV2P53kXSPpoZ79ESedIukHS9bnuA5LeXZn+hKQzJT0EvCKpd95fN+Z2L5B0eqV+37zPV0h6GNi3w/qekPTB/LyXpC9Leiyve5akoZLuztUfzPv9hFz/Q5Jm5+39taR3VZb7v3PbX5J0PbBlZ9tbqX+qpEdy/Ycl7Z3L35Hfq88rdUceVZnnDe+lLsr6SLpQ0lNKPQ3fldS3spzReTtezNs+UtL5wPuAS/I2X9KhvfvmZVX/pj4saXZ322lZRPjRQx7AE8AHgR8D5+WyTwJ35udvAwLoXZnnTuCT+fkngFXAyUAv4DzgKeBSoA9wOPASsFWuf1V+fXCe/m3gl3laf2BhXlZvYG/gWWDPyrwvAO8lfZHaspPtuQv4DulDbTiwDDi00tZfdrMvXjc9b/cU4E3AnsCrwB3A24FtgIeBsbnudsCHgX7A1sCPgJ9UlnUPcCGwBamr8UXg2jxtMPAcMCpv12H5dVveJy8Cu+e6O7Tvj07afw7wGnAcsDnwBWABsHnldz0bGAr0zeuaBfxrbtfbgceBI3L9C4BfAAPzPHOARR3fO/n5F4HfArsDAt4NbFfZj7tW5tsbeAbYn/SeGZuX1Se340ng83kbjsvbdF4X23w88DQpPAXsSjpS3hyYD3w5L/MDpPdd+368ig7vpS7KvpXfAwPz7/W/ga/lZeyX6x+W6w8G9uj4N9Lh/bRrfv4wcGRl2k3Av9T9ebAxPGpvgB8t/GX/LaD2yn9sbax9QM2rTPtfuf5bKmXPAcPz86uA6yrTtgJW5w/AE4BfdGjf94DxlXmv7mZbhuZlbV0p+xpwVaWtaxtQ7628ngWcWXn9DeBbXSxrOLAiP9+RFOL9KtOv5W8BdSZwTYf5p5E+uPsDz5PCr+8afpfnAPdWXm8GLAHeV/ld/2Nl+v7AUx2WcTbw/fz8cWBkZdo4ug6oR4HRXbSrY0BdBpzboc6jwPtJX1wWA6pM+zVdB9Q04HOdlL8P+AOwWaVsEnBOV++ljmWkwHsF2KVSdiCwoPLevKiLdt1J9wF1JvCD/HwgsBLYYV3/jnvSw33TPVBEzJF0C3AW8Mhazr608vyPeXkdy7aqvF5YWe/LkpYDg0jffPeX9Hylbm/gms7m7cQgYHlEvFQpexIY0chGdKHjdnR8/VYASf2Ai4CRwIA8fWul8xjt7VpZmXchKVAhbffxkv6hMn1z4H8i4pXcLfYF4ApJvyJ90/5dF+2t7tu/KI26G9TZ9LzeQR32dy/SURN5vmr9J7tYJ3lbHutmetVOwFhJn62UbZHXF8DTkT+512O9g4CFEfGXDssZXHnd2XupWtZGOiKeJam9TKR91L7uqd20rTvXAo9I2gr4COmL2ZJ1XFaP4nNQPdd44FRe/0fcPqCgX6Xsreu5nvYPZvIf6EDSt+aFwF0RsW3lsVVEfLoyb3e32l8MDJS0daVsR1IXULP9C6l7a/+IeBPpSADSB9qS3K7qPhxaeb6QdARV3e7+EXEBQERMi4jDSN17vwMu76Yd1X27GTCEtF/aVfffQtLRQHW9W0fEqDx9SYd27tjNehcCu3QzvWPd8zust19ETMrrHKxKIqzjehcDQ/M+qC6n+l7o7L1ULXuW9CVkz0o7t4mI9i9b3W1zt/8SIiKeJnX7HgN8nNd/CbNuOKB6qIiYD1wPnF4pW0b6o/5YPhH+jzT+QdSVUZIOygMMzgXui4iFwC3AbpI+Lmnz/NhX0jsabP9CUnfQ1yRtmU+8nwL8YD3b24itSR9mz0saSAr79nY9CcwEzpG0haQDgerR0rXAP0g6Iu/jLZWuORoi6S2SjlK6DOBV4GVSN2ZX9pF0bD4Bf0ae594u6t4PvJgHTvTN695LUvtgiMnA2UoDQIYAn+1iOZAGoJwraZiSd0naLk9bSjq/1e5y4J8k7Z/r9pf09/mLxT2k7tDTlQZxHEs619Pder8gaZ+8rF2VBt3cR/py9aX8PjqEtM+v62ZZr5OPvi4HLpK0PYCkwZKOyFWuAE6WdKikzfK0PbrY5s5cDXyJ1C1+U6Pt6ukcUD3bV0nnPapOJZ0Ef440WODX67mOH5I+wJcD+wAfBchdc4cDY0jfgP8AfJ108rxRJ5LOmy0m/dGPj4jp69neRnyLNPDgWVIg3Nph+kdJ5y+eIw0kuZ4UHu3BOpp0Qn8Z6Zv5F0l/i5uRjs4Wk/bX+4F/7qYdN5PO5a0gfTM/NiJe66xiRKwmfWgPJw2meJb0gb9NrvJvpG6xBcBtdP8t/5ukQLuNNKjjirw/IJ0bm5hH030kImaS3lOX5HbOJ53/IyL+DBybX6/I2/LjrlYaET8Czie9p14CfgIMzMs5Cjgyb9d3gJO66Rrtypm5ffdKehG4nXSkTETcTxrQcxHp/O1dpO5LSIN/jlMaAXlxF8u+Kde/KXzpQ8P0+u5fM9vQlIZP/y4ixq+xcuPLPId0Ev5jG2qZ1lySHgM+FRG3192WjYWPoMw2sNxVuUvuChpJOmL6Sd3tsvpI+jDpXNXP627LxqRpASXpSqULN+dUygYqXZg5L/8ckMsl6WKliy0fUr74Lk8bm+vPU+Ui0NwP/ds8z8UdTrSa1emtpKHHLwMXA5+OiN/U2iKrjdKtxC4DTusw0tDWoGldfJIOJv2BXh0Re+WyfycNwb1A0lnAgIg4U9Io0knZUaTrNb4dEfvnE9AzSUOHg3Rtyj4R0X4D0M+RzgFMBS6OiJ81ZWPMzKzlmnYEFRF3k070Vo0GJubnE4GjK+VXR3IvsK2kHYAjgOkRsTwiVgDTgZF52psi4p58DcXVlWWZmdkmoNUX6r6l/QK1iFjSPpyTdC1O9aK5Rbmsu/JFnZR3StI40pXx9O/ff5899tijq6pmZtZks2bNejYi2tZUr5Q7SXR2/ijWobxTETEBmAAwYsSImDlz5rq00czMNgBJ3d0x5K9aPYpvae6eI/98Jpcv4vVXsbdfEd9d+ZBOys3MbBPR6oCaQropJvnnzZXyk/JovgOAF3JX4DTg8Hx1+wDShZ3T8rSXlP5tgYCTKssyM7NNQNO6+CRNAg4h/T+gRaS7CVwATFb6fz1PkW6fD2kU3ijSVdwrSVdsExHLJZ0LzMj1vhoR7QMvPk26I3Ff4Gf5YWZmm4gedycJn4MyM6uXpFkRscb/POA7SZiZWZEcUGZmViQHlJmZFckBZWZmRXJAmZlZkRxQZmZWJAeUmZkVyQFlZmZFckCZmVmRHFBmZlYkB5SZmRXJAWVmZkVyQJmZWZEcUGZmViQHlJmZFckBZWZmRWraf9Q1M7PWmjChNesZN64163FAmVnxNrUPXmuMu/jMzKxIPoIyq5GPDMy65iMoMzMrkgPKzMyK5IAyM7MiOaDMzKxIDigzMyuSA8rMzIrkgDIzsyI5oMzMrEi1BJSkz0maI2mupDNy2TmSnpY0Oz9GVeqfLWm+pEclHVEpH5nL5ks6q45tMTOz5mj5nSQk7QWcCuwH/Bm4VdJP8+SLIuLCDvXfCYwB9gQGAbdL2i1PvhQ4DFgEzJA0JSIebsFmmJlZk9Vxq6N3APdGxEoASXcBx3RTfzRwXUS8CiyQNJ8UbgDzI+LxvJzrcl0HlJnZJqCOLr45wMGStpPUDxgFDM3TPiPpIUlXShqQywYDCyvzL8plXZW/gaRxkmZKmrls2bINuS1mZtYkLQ+oiHgE+DowHbgVeBBYBVwG7AIMB5YA38izqLPFdFPe2TonRMSIiBjR1ta2fhtgZmYtUcsgiYi4IiL2joiDgeXAvIhYGhGrI+IvwOX8rRtvEX87wgIYAizuptzMzDYBdY3i2z7/3BE4FpgkaYdKlWNIXYEAU4AxkvpI2hkYBtwPzACGSdpZ0hakgRRTWrUNZmbWXHX9P6gbJW0HvAacFhErJF0jaTipm+4J4FMAETFX0mTS4IdVuf5qAEmfAaYBvYArI2Ju6zfFzMyaoZaAioj3dVL28W7qnw+c30n5VGDqhm2dmZmVwHeSMDOzIjmgzMysSA4oMzMrkgPKzMyK5IAyM7MiOaDMzKxIDigzMyuSA8rMzIrkgDIzsyI5oMzMrEgOKDMzK5IDyszMiuSAMjOzIjmgzMysSA4oMzMrkgPKzMyK5IAyM7MiOaDMzKxIDigzMyuSA8rMzIrkgDIzsyI5oMzMrEi9626AbZomTGjNesaNa816zKz1fARlZmZFckCZmVmRHFBmZlYkB5SZmRWploCS9DlJcyTNlXRGLhsoabqkefnngFwuSRdLmi/pIUl7V5YzNtefJ2lsHdtiZmbN0fKAkrQXcCqwH/Bu4EOShgFnAXdExDDgjvwa4EhgWH6MAy7LyxkIjAf2z8sa3x5qZma28avjCOodwL0RsTIiVgF3AccAo4GJuc5E4Oj8fDRwdST3AttK2gE4ApgeEcsjYgUwHRjZyg0xM7PmqSOg5gAHS9pOUj9gFDAUeEtELAHIP7fP9QcDCyvzL8plXZWbmdkmoOUX6kbEI5K+TjrieRl4EFjVzSzqbDHdlL9xAdI4UvcgO+6441q118zM6lHLIImIuCIi9o6Ig4HlwDxgae66I/98JldfRDrCajcEWNxNeWfrmxARIyJiRFtb24bdGDMza4q6RvFtn3/uCBwLTAKmAO0j8cYCN+fnU4CT8mi+A4AXchfgNOBwSQPy4IjDc5mZmW0C6roX342StgNeA06LiBWSLgAmSzoFeAo4PtedSjpPNR9YCZwMEBHLJZ0LzMj1vhoRy1u5EWZm1jy1BFREvK+TsueAQzspD+C0LpZzJXDlBm+gmZnVzneSMDOzIjmgzMysSA4oMzMrkgPKzMyK5IAyM7MiOaDMzKxIDigzMyuSA8rMzIrkgDIzsyI5oMzMrEgOKDMzK5IDyszMiuSAMjOzIjmgzMysSA4oMzMrkgPKzMyK5IAyM7MiOaDMzKxIDQWUpOMlbZ2f/z9JP5a0d3ObZmZmPVmjR1BfiYiXJB0EHAFMBC5rXrPMzKynazSgVueffw9cFhE3A1s0p0lmZmaNB9TTkr4HfASYKqnPWsxrZma21hoNmY8A04CREfE8MBD4YtNaZWZmPV5DARURK4FngINy0SpgXrMaZWZm1ugovvHAmcDZuWhz4NpmNcrMzKzRLr5jgKOAVwAiYjGwdbMaZWZm1mhA/TkiAggASf2b1yQzM7PGA2pyHsW3raRTgduBy5vXLDMz6+kaHSRxIXADcCOwO/CvEfGf67pSSZ+XNFfSHEmTJG0p6SpJCyTNzo/hua4kXSxpvqSHqnewkDRW0rz8GLuu7TEzs/L0XlMFSb2AaRHxQWD6+q5Q0mDgdOCdEfFHSZOBMXnyFyPihg6zHAkMy4/9SXew2F/SQGA8MILU9ThL0pSIWLG+bTQzs/qt8QgqIlYDKyVtswHX2xvoK6k30A9Y3E3d0cDVkdxL6mbcgXTLpekRsTyH0nRg5AZso5mZ1ajRc1B/An4r6Yrc3XaxpIvXZYUR8TRwIfAUsAR4ISJuy5PPz914F+W7VQAMBhZWFrEol3VV/gaSxkmaKWnmsmXL1qXZZmbWYo0G1E+BrwB3A7Mqj7UmaQDpqGhnYBDQX9LHSNdY7QHsS7pTxZnts3SymOim/I2FERMiYkREjGhra1uXZpuZWYut8RwUQERMlLQFsFsuejQiXlvHdX4QWBARywAk/Rh4T0S0X/j7qqTvA1/IrxcBQyvzDyF1CS4CDulQfuc6tsnMzArT6J0kDiHd2uhS4DvA7yUdvI7rfAo4QFI/SQIOBR7J55XIZUcDc3L9KcBJeTTfAaQuwSWkewMeLmlAPio7PJeZmdkmoKEjKOAbwOER8SiApN2AScA+a7vCiLhP0g3AA6R7+v0GmAD8TFIbqetuNvBPeZapwChgPrASODkvZ7mkc4EZud5XI2L52rbHzMzK1GhAbd4eTgAR8XtJm6/rSiNiPGmIeNUHuqgbwGldTLsSuHJd22FmZuVqNKBmSroCuCa//ijrOEjCzMysEY0G1KdJRzGnk7rg7iadizIzM2uKRgOqN/DtiPgm/PXuEn26n8XMzGzdNXod1B1A38rrvqQbxpqZmTVFowG1ZUS83P4iP+/XnCaZmZk1HlCvdLiL+Ajgj81pkpmZWePnoM4AfiRpMel2QoOAE5rWKjMz6/G6PYKStK+kt0bEDNJ98q4nXVx7K7CgBe0zM7Meak1dfN8D/pyfHwh8mXS7oxWkuz+YmZk1xZq6+HpVbh90AjAhIm4EbpQ0u7lNMzOznmxNR1C98j8VhHRT159XpjV6/srMzGytrSlkJgF3SXqWNGrvFwCSdgVeaHLbzMysB+s2oCLifEl3ADsAt+Ubt0I68vpssxtnZmY91xq76SLi3k7Kft+c5piZmSWNXqhrZmbWUg4oMzMrkgPKzMyK5IAyM7MiOaDMzKxIvth2LU1o0Q2exo1rzXrMzErlIygzMyuSA8rMzIrkgDIzsyI5oMzMrEgOKDMzK5IDyszMiuSAMjOzItUSUJI+L2mupDmSJknaUtLOku6TNE/S9ZK2yHX75Nfz8/S3VZZzdi5/VNIRdWyLmZk1R8sDStJg4HRgRETsBfQCxgBfBy6KiGHACuCUPMspwIqI2BW4KNdD0jvzfHsCI4HvSOrVym0xM7PmqauLrzfQN/87+X7AEuADwA15+kTg6Px8dH5Nnn6oJOXy6yLi1YhYAMwH9mtR+83MrMlaHlAR8TRwIfAUKZheAGYBz0fEqlxtETA4Px8MLMzzrsr1t6uWdzKPmZlt5Oro4htAOvrZGRgE9AeO7KRq+7+XVxfTuirvbJ3jJM2UNHPZsmVr32gzM2u5Orr4PggsiIhlEfEa8GPgPcC2ucsPYAiwOD9fBAwFyNO3AZZXyzuZ53UiYkJEjIiIEW1tbRt6e8zMrAnqCKingAMk9cvnkg4FHgb+Bzgu1xkL3JyfT8mvydN/HhGRy8fkUX47A8OA+1u0DWZm1mQt/3cbEXGfpBuAB4BVwG+ACcBPgesknZfLrsizXAFcI2k+6chpTF7OXEmTSeG2CjgtIla3dGPMzKxpavl/UBExHhjfofhxOhmFFxF/Ao7vYjnnA+dv8AaamVntfCcJMzMrkgPKzMyK5IAyM7MiOaDMzKxIDigzMyuSA8rMzIrkgDIzsyI5oMzMrEgOKDMzK5IDyszMiuSAMjOzIjmgzMysSA4oMzMrkgPKzMyK5IAyM7MiOaDMzKxIDigzMyuSA8rMzIrkgDIzsyI5oMzMrEgOKDMzK5IDyszMiuSAMjOzIjmgzMysSA4oMzMrkgPKzMyK5IAyM7MiOaDMzKxILQ8oSbtLml15vCjpDEnnSHq6Uj6qMs/ZkuZLelTSEZXykblsvqSzWr0tZmbWPL1bvcKIeBQYDiCpF/A0cBNwMnBRRFxYrS/pncAYYE9gEHC7pN3y5EuBw4BFwAxJUyLi4ZZsiJmZNVXLA6qDQ4HHIuJJSV3VGQ1cFxGvAgskzQf2y9PmR8TjAJKuy3UdUGZmm4C6z0GNASZVXn9G0kOSrpQ0IJcNBhZW6izKZV2Vv4GkcZJmSpq5bNmyDdd6MzNrmtoCStIWwFHAj3LRZcAupO6/JcA32qt2Mnt0U/7GwogJETEiIka0tbWtV7vNzKw16uziOxJ4ICKWArT/BJB0OXBLfrkIGFqZbwiwOD/vqtzMzDZydXbxnUile0/SDpVpxwBz8vMpwBhJfSTtDAwD7gdmAMMk7ZyPxsbkumZmtgmo5QhKUj/S6LtPVYr/XdJwUjfdE+3TImKupMmkwQ+rgNMiYnVezmeAaUAv4MqImNuyjTAzs6aqJaAiYiWwXYeyj3dT/3zg/E7KpwJTN3gDzcysdnWP4jMzM+uUA8rMzIrkgDIzsyI5oMzMrEgOKDMzK5IDyszMiuSAMjOzIjmgzMysSA4oMzMrkgPKzMyK5IAyM7MiOaDMzKxIDigzMyuSA8rMzIrkgDIzsyI5oMzMrEgOKDMzK5IDyszMiuSAMjOzIjmgzMysSA4oMzMrkgPKzMyK5IAyM7MiOaDMzKxIDigzMyuSA8rMzIrkgDIzsyI5oMzMrEgtDyhJu0uaXXm8KOkMSQMlTZc0L/8ckOtL0sWS5kt6SNLelWWNzfXnSRrb6m0xM7PmaXlARcSjETE8IoYD+wArgZuAs4A7ImIYcEd+DXAkMCw/xgGXAUgaCIwH9gf2A8a3h5qZmW386u7iOxR4LCKeBEYDE3P5RODo/Hw0cHUk9wLbStoBOAKYHhHLI2IFMB0Y2drmm5lZsygi6lu5dCXwQERcIun5iNi2Mm1FRAyQdAtwQUT8MpffAZwJHAJsGRHn5fKvAH+MiAs7Wc840tEXwO7Ao83crm68GXi2pnVvTLyfGuP91Djvq8a0aj/tFBFta6rUuwUN6ZSkLYCjgLPXVLWTsuim/I2FEROACWvVwCaQNDMiRtTdjtJ5PzXG+6lx3leNKW0/1dnFdyTp6Glpfr00d92Rfz6TyxcBQyvzDQEWd1NuZmabgDoD6kRgUuX1FKB9JN5Y4OZK+Ul5NN8BwAsRsQSYBhwuaUAeHHF4LjMzs01ALV18kvoBhwGfqhRfAEyWdArwFHB8Lp8KjALmk0b8nQwQEcslnQvMyPW+GhHLW9D89VF7N+NGwvupMd5PjfO+akxR+6nWQRJmZmZdqXuYuZmZWaccUGZmViQHVItIOkZSSNqj7raUStLqfPurByU9IOk9dbepRJLeKuk6SY9JeljSVEm71d2u0lTeT3Pze+r/SvJnXgeV/dT+OGvNc7WGz0G1iKTJwA6k2zmdU3NziiTp5YjYKj8/AvhyRLy/5mYVRZKAXwMTI+K7uWw4sHVE/KLWxhWmw/tpe+CHwK8iYny9LStLdT+Vxt8mWkDSVsB7gVOAMTU3Z2PxJmBF3Y0o0N8Br7WHE0BEzHY4dS8iniHdTeYzOeRtI1DbnSR6mKOBWyPi95KWS9o7Ih6ou1EF6itpNrAl6WjzAzW3p0R7AbPqbsTGKCIez1182wNL11S/B2n/u2v3tYi4vrbWVDigWuNE4Fv5+XX5tQPqjf6Y73KPpAOBqyXtFe6Htg3HR09v9Ne/u9I4oJpM0nakI4G9JAXQCwhJX/IHb9ci4h5Jbwba+NttrwzmAsfV3YiNkaS3A6vx+2mj4XNQzXcc6d+F7BQRb4uIocAC4KCa21W0PNqxF/Bc3W0pzM+BPpJObS+QtK8kDybphqQ24LvAJf5iuPHwEVTznUi6jVPVjcD/AXxi+/WqfeECxkbE6jobVJqICEnHAN/Kw4H/BDwBnFFrw8rU/n7aHFgFXAN8s94mFanjOahbI6KIoeYeZm5mZkVyF5+ZmRXJAWVmZkVyQJmZWZEcUGZmViQHlJmZFckBZVYTSW+R9ENJj0uaJemePITczHBAmdUi37D0J8DdEfH2iNiHdCPhIR3q+VpF67EcUGb1+ADw5w53JX8yIv5T0ick/UjSfwO3KfkPSXMk/VbSCQCSDpF0S/v8ki6R9In8/AlJX5d0f37s2uLtM1tv/nZmVo896f6GwQcC74qI5ZI+DAwH3g28GZgh6e4G1vFiROwn6STSzYo/tL6NNmslH0GZFUDSpfm/vs7IRdMjYnl+fhAwKSJWR8RS4C5g3wYWO6ny88AN22Kz5nNAmdVjLrB3+4uIOA04lHT3doBXKnW7+hcRq3j93/CWHaZHF8/NNgoOKLN6/BzYUtKnK2X9uqh7N3CCpF75rtwHA/cDTwLvlNRH0jakgKs6ofLzng3XdLPW8Dkosxrku5IfDVwk6UvAMtJR05lA3w7VbyJ10T1IOhL6UkT8AUDSZOAhYB7wmw7z9ZF0H+mL6InN2hazZvHdzM02QZKeAEZExLN1t8VsXbmLz8zMiuQjKDMzK5KPoMzMrEgOKDMzK5IDyszMiuSAMjOzIjmgzMysSP8fUAE6w2UHZ+8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from collections import namedtuple\n",
    "\n",
    "# 5 cases\n",
    "n_groups = 5\n",
    "\n",
    "# Set scores\n",
    "score = (8165, 9110, 9664, 9689, 9705)\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# format table\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "opacity = 0.4\n",
    "error_config = {'ecolor': '0.3'}\n",
    "rects1 = ax.bar(index, score, bar_width,\n",
    "                alpha=opacity, color='b',\n",
    "                 error_kw=error_config,\n",
    "                )\n",
    "\n",
    "# plot table\n",
    "plt.ylim(7000,10000)\n",
    "ax.set_xlabel('Group')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Number of images predicted correctly')\n",
    "ax.set_xticks(index + bar_width / 10)\n",
    "ax.set_xticklabels(('A', 'B', 'C', 'D', 'E'))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Simple explanation on supervised vs unsupervised machine learning - https://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/\n",
    "2. MNIST Database Website - http://yann.lecun.com/exdb/mnist/\n",
    "3. Explanation on the MNIST database and how to read it in memory - https://github.com/yonjeremy/emerging-technologies-assesment/blob/master/mnist-dataset.ipynb\n",
    "4. Official Keras documentation website - https://keras.io/\n",
    "5. Explanation on Activations - https://keras.io/activations/\n",
    "6. Good guide on Convolutional neural networks  - https://machinelearningmastery.com/handwritten-digit-recognition-using-convolutional-neural-networks-python-keras/\n",
    "7. Code snippets from here - https://github.com/ianmcloughlin/jupyter-teaching-notebooks/blob/master/mnist.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
